{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/blank54/anaconda3/envs/study/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/data/blank54/anaconda3/envs/study/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/data/blank54/anaconda3/envs/study/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/data/blank54/anaconda3/envs/study/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/data/blank54/anaconda3/envs/study/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/data/blank54/anaconda3/envs/study/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/data/blank54/anaconda3/envs/study/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/data/blank54/anaconda3/envs/study/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/data/blank54/anaconda3/envs/study/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/data/blank54/anaconda3/envs/study/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/data/blank54/anaconda3/envs/study/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/data/blank54/anaconda3/envs/study/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from silence_tensorflow import silence_tensorflow\n",
    "silence_tensorflow()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=DeprecationWarning)\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle as pk\n",
    "import itertools\n",
    "from copy import deepcopy\n",
    "from collections import defaultdict\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Model, Input\n",
    "from keras.layers import Dense, Bidirectional, LSTM, TimeDistributed\n",
    "from keras_contrib.layers import CRF\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = {'NON': 0,     #None\n",
    "              'PER': 1,     #PERSON\n",
    "              'FOD': 2,}    #FOOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = deepcopy([l for l in label_dict.keys()])\n",
    "\n",
    "cnt = deepcopy(len(label_dict))\n",
    "label_dict['__PAD__'] = cnt\n",
    "label_dict['__UNK__'] = cnt+1\n",
    "        \n",
    "label2id = label_dict\n",
    "id2label = {int(i): str(l) for i, l in enumerate(label_dict.keys())}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sents = {'sent1': 'Sam likes pizza',\n",
    "              'sent2': 'Erik eats pizza',\n",
    "              'sent3': 'Erik and Sam are drinking soda',\n",
    "              'sent4': 'Flora cooks chicken',\n",
    "              'sent5': 'Sam ordered a chicken',\n",
    "              'sent6': 'Flora likes chicken sandwitch',\n",
    "              'sent7': 'Erik likes to drink soda'}\n",
    "data_labels = {'sent1': [1, 0, 2],\n",
    "               'sent2': [1, 0, 2],\n",
    "               'sent3': [1, 0, 1, 0, 0, 2],\n",
    "               'sent4': [1, 0, 2],\n",
    "               'sent5': [1, 0, 0, 2],\n",
    "               'sent6': [1, 0, 2, 2],\n",
    "               'sent7': [1, 0, 0, 0, 2]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = []\n",
    "for tag, sent in data_sents.items():\n",
    "    words = [str(w) for w in sent.split()]\n",
    "    labels = data_labels[tag]\n",
    "    docs.append((tag, words, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = list(set(itertools.chain(*[doc[1] for doc in docs])))\n",
    "words.append('__PAD__')\n",
    "words.append('__UNK__')\n",
    "\n",
    "word2id = {w: i for i, w in enumerate(words)}\n",
    "id2word = {i: w for i, w in enumerate(words)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sent_len = 10\n",
    "test_size = 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Sentence Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_words = []\n",
    "Y_labels = []\n",
    "for doc in docs:\n",
    "    X_words.append([word2id[w] for w in doc[1]])\n",
    "    Y_labels.append(doc[2])\n",
    "\n",
    "X_words_pad = pad_sequences(\n",
    "    maxlen=max_sent_len,\n",
    "    sequences=X_words,\n",
    "    padding='post',\n",
    "    value=word2id['__PAD__'])\n",
    "Y_labels_pad = pad_sequences(\n",
    "    maxlen=max_sent_len,\n",
    "    sequences=Y_labels,\n",
    "    padding='post',\n",
    "    value=label2id['__PAD__'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_for_w2v = [doc[1] for doc in docs]\n",
    "w2v_model = Word2Vec(sentences=docs_for_w2v,\n",
    "                     size=100,\n",
    "                     window=5,\n",
    "                     min_count=0,\n",
    "                     iter=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vector = {w: w2v_model.wv[w] for w in w2v_model.wv.vocab.keys()}\n",
    "feature_size = w2v_model.vector_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vector['__PAD__'] = np.zeros(feature_size)\n",
    "word2vector['__UNK__'] = np.zeros(feature_size)\n",
    "\n",
    "X_embedded = np.zeros((len(docs), max_sent_len, feature_size))\n",
    "Y_embedded = np.zeros((len(docs), max_sent_len, len(label2id)))\n",
    "\n",
    "for i in range(len(docs)):\n",
    "    for j, word_id in enumerate(X_words_pad[i]):\n",
    "        Y_embedded[i] = to_categorical(Y_labels_pad[i], num_classes=(len(label2id)))\n",
    "        for k in range(feature_size):\n",
    "            word = id2word[word_id]\n",
    "            X_embedded[i, j, k] = word2vector[word][k]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X_embedded, Y_embedded, test_size=test_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Model Development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "_input = Input(shape=(max_sent_len, feature_size))\n",
    "ner_model = Bidirectional(LSTM(units=512,\n",
    "                           return_sequences=True,\n",
    "                           recurrent_dropout=0.2))(_input)\n",
    "ner_model = TimeDistributed(Dense(units=100,\n",
    "                              activation='relu'))(ner_model)\n",
    "crf = CRF(len(label2id))\n",
    "_output = crf(ner_model)\n",
    "\n",
    "ner_model = Model(inputs=_input, outputs=_output)\n",
    "ner_model.compile(optimizer='rmsprop',\n",
    "                  loss=crf.loss_function,\n",
    "                  metrics=[crf.accuracy])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3 samples, validate on 1 samples\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 5s 2s/step - loss: 1.8804 - crf_viterbi_accuracy: 0.2667 - val_loss: 1.4818 - val_crf_viterbi_accuracy: 0.4000\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 1.1885 - crf_viterbi_accuracy: 0.5667 - val_loss: 0.7822 - val_crf_viterbi_accuracy: 0.6000\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.9444 - crf_viterbi_accuracy: 0.6667 - val_loss: 1.2186 - val_crf_viterbi_accuracy: 0.6000\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 1.0136 - crf_viterbi_accuracy: 0.6333 - val_loss: 0.9125 - val_crf_viterbi_accuracy: 0.6000\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.9249 - crf_viterbi_accuracy: 0.6000 - val_loss: 0.8670 - val_crf_viterbi_accuracy: 0.6000\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.8833 - crf_viterbi_accuracy: 0.6667 - val_loss: 0.7809 - val_crf_viterbi_accuracy: 0.7000\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.8749 - crf_viterbi_accuracy: 0.7333 - val_loss: 0.7699 - val_crf_viterbi_accuracy: 0.7000\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.8237 - crf_viterbi_accuracy: 0.7000 - val_loss: 0.7469 - val_crf_viterbi_accuracy: 0.7000\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 0.7816 - crf_viterbi_accuracy: 0.7000 - val_loss: 0.9418 - val_crf_viterbi_accuracy: 0.6000\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.8326 - crf_viterbi_accuracy: 0.6667 - val_loss: 0.7875 - val_crf_viterbi_accuracy: 0.7000\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.7537 - crf_viterbi_accuracy: 0.6667 - val_loss: 0.5774 - val_crf_viterbi_accuracy: 0.7000\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.7631 - crf_viterbi_accuracy: 0.7333 - val_loss: 0.6384 - val_crf_viterbi_accuracy: 0.8000\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.7774 - crf_viterbi_accuracy: 0.7333 - val_loss: 0.7298 - val_crf_viterbi_accuracy: 0.7000\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 0.7843 - crf_viterbi_accuracy: 0.7000 - val_loss: 0.6770 - val_crf_viterbi_accuracy: 0.7000\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.7133 - crf_viterbi_accuracy: 0.7000 - val_loss: 0.7135 - val_crf_viterbi_accuracy: 0.7000\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.7641 - crf_viterbi_accuracy: 0.7667 - val_loss: 0.8105 - val_crf_viterbi_accuracy: 0.7000\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 0.7619 - crf_viterbi_accuracy: 0.6667 - val_loss: 0.6524 - val_crf_viterbi_accuracy: 0.8000\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.7638 - crf_viterbi_accuracy: 0.7000 - val_loss: 0.7129 - val_crf_viterbi_accuracy: 0.7000\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.7813 - crf_viterbi_accuracy: 0.7000 - val_loss: 0.6683 - val_crf_viterbi_accuracy: 0.8000\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.6512 - crf_viterbi_accuracy: 0.7000 - val_loss: 0.7447 - val_crf_viterbi_accuracy: 0.7000\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.8056 - crf_viterbi_accuracy: 0.7000 - val_loss: 0.6710 - val_crf_viterbi_accuracy: 0.8000\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.7723 - crf_viterbi_accuracy: 0.7667 - val_loss: 0.7826 - val_crf_viterbi_accuracy: 0.5000\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.7230 - crf_viterbi_accuracy: 0.7667 - val_loss: 0.7795 - val_crf_viterbi_accuracy: 0.7000\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 0.6378 - crf_viterbi_accuracy: 0.8000 - val_loss: 0.6612 - val_crf_viterbi_accuracy: 0.8000\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.6737 - crf_viterbi_accuracy: 0.7667 - val_loss: 0.7292 - val_crf_viterbi_accuracy: 0.7000\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.7505 - crf_viterbi_accuracy: 0.7000 - val_loss: 0.6297 - val_crf_viterbi_accuracy: 0.8000\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.6328 - crf_viterbi_accuracy: 0.7667 - val_loss: 0.7583 - val_crf_viterbi_accuracy: 0.7000\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.6716 - crf_viterbi_accuracy: 0.7333 - val_loss: 0.6246 - val_crf_viterbi_accuracy: 0.8000\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.7138 - crf_viterbi_accuracy: 0.7667 - val_loss: 0.7499 - val_crf_viterbi_accuracy: 0.7000\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.6904 - crf_viterbi_accuracy: 0.7333 - val_loss: 0.6897 - val_crf_viterbi_accuracy: 0.8000\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.7012 - crf_viterbi_accuracy: 0.7333 - val_loss: 0.6343 - val_crf_viterbi_accuracy: 0.8000\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.6820 - crf_viterbi_accuracy: 0.7333 - val_loss: 0.6142 - val_crf_viterbi_accuracy: 0.8000\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.7204 - crf_viterbi_accuracy: 0.7333 - val_loss: 0.7323 - val_crf_viterbi_accuracy: 0.5000\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.7126 - crf_viterbi_accuracy: 0.6333 - val_loss: 0.6387 - val_crf_viterbi_accuracy: 0.8000\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.5956 - crf_viterbi_accuracy: 0.7333 - val_loss: 0.7098 - val_crf_viterbi_accuracy: 0.7000\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.5737 - crf_viterbi_accuracy: 0.7333 - val_loss: 0.6424 - val_crf_viterbi_accuracy: 0.8000\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.6611 - crf_viterbi_accuracy: 0.7333 - val_loss: 0.6745 - val_crf_viterbi_accuracy: 0.7000\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.6666 - crf_viterbi_accuracy: 0.6667 - val_loss: 0.6114 - val_crf_viterbi_accuracy: 0.8000\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.5998 - crf_viterbi_accuracy: 0.7667 - val_loss: 0.5984 - val_crf_viterbi_accuracy: 0.8000\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.5663 - crf_viterbi_accuracy: 0.7333 - val_loss: 0.7487 - val_crf_viterbi_accuracy: 0.6000\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.5574 - crf_viterbi_accuracy: 0.8333 - val_loss: 0.6028 - val_crf_viterbi_accuracy: 0.8000\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.6430 - crf_viterbi_accuracy: 0.7333 - val_loss: 0.5801 - val_crf_viterbi_accuracy: 0.8000\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.5821 - crf_viterbi_accuracy: 0.8000 - val_loss: 0.7873 - val_crf_viterbi_accuracy: 0.5000\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.6697 - crf_viterbi_accuracy: 0.7333 - val_loss: 0.5780 - val_crf_viterbi_accuracy: 0.7000\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.6297 - crf_viterbi_accuracy: 0.7667 - val_loss: 0.6343 - val_crf_viterbi_accuracy: 0.8000\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.5659 - crf_viterbi_accuracy: 0.7667 - val_loss: 0.5813 - val_crf_viterbi_accuracy: 0.8000\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.6220 - crf_viterbi_accuracy: 0.7333 - val_loss: 0.6038 - val_crf_viterbi_accuracy: 0.7000\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.5925 - crf_viterbi_accuracy: 0.7667 - val_loss: 0.6751 - val_crf_viterbi_accuracy: 0.8000\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.5782 - crf_viterbi_accuracy: 0.7667 - val_loss: 0.5975 - val_crf_viterbi_accuracy: 0.8000\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 67ms/step - loss: 0.5540 - crf_viterbi_accuracy: 0.7333 - val_loss: 0.6826 - val_crf_viterbi_accuracy: 0.6000\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.5089 - crf_viterbi_accuracy: 0.7667 - val_loss: 0.6263 - val_crf_viterbi_accuracy: 0.8000\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.5892 - crf_viterbi_accuracy: 0.7000 - val_loss: 0.5749 - val_crf_viterbi_accuracy: 0.8000\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.5837 - crf_viterbi_accuracy: 0.7333 - val_loss: 0.6621 - val_crf_viterbi_accuracy: 0.7000\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.5293 - crf_viterbi_accuracy: 0.7333 - val_loss: 0.5736 - val_crf_viterbi_accuracy: 0.8000\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.4895 - crf_viterbi_accuracy: 0.8000 - val_loss: 0.4838 - val_crf_viterbi_accuracy: 0.8000\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.6397 - crf_viterbi_accuracy: 0.7000 - val_loss: 0.5627 - val_crf_viterbi_accuracy: 0.8000\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.4593 - crf_viterbi_accuracy: 0.8667 - val_loss: 0.6040 - val_crf_viterbi_accuracy: 0.8000\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.6708 - crf_viterbi_accuracy: 0.7667 - val_loss: 0.5351 - val_crf_viterbi_accuracy: 0.8000\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.5447 - crf_viterbi_accuracy: 0.7333 - val_loss: 0.6159 - val_crf_viterbi_accuracy: 0.6000\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.5017 - crf_viterbi_accuracy: 0.8333 - val_loss: 0.4828 - val_crf_viterbi_accuracy: 0.8000\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.5906 - crf_viterbi_accuracy: 0.7667 - val_loss: 0.6797 - val_crf_viterbi_accuracy: 0.6000\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.4757 - crf_viterbi_accuracy: 0.8333 - val_loss: 0.6493 - val_crf_viterbi_accuracy: 0.7000\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.5040 - crf_viterbi_accuracy: 0.8333 - val_loss: 0.6127 - val_crf_viterbi_accuracy: 0.6000\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.5061 - crf_viterbi_accuracy: 0.8000 - val_loss: 0.5453 - val_crf_viterbi_accuracy: 0.8000\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.4856 - crf_viterbi_accuracy: 0.7667 - val_loss: 0.5973 - val_crf_viterbi_accuracy: 0.7000\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.4686 - crf_viterbi_accuracy: 0.8667 - val_loss: 0.4841 - val_crf_viterbi_accuracy: 0.8000\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 0.4602 - crf_viterbi_accuracy: 0.8000 - val_loss: 0.6270 - val_crf_viterbi_accuracy: 0.6000\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.4447 - crf_viterbi_accuracy: 0.8667 - val_loss: 0.5054 - val_crf_viterbi_accuracy: 0.8000\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.4392 - crf_viterbi_accuracy: 0.8333 - val_loss: 0.5822 - val_crf_viterbi_accuracy: 0.7000\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 0.4315 - crf_viterbi_accuracy: 0.8000 - val_loss: 0.5861 - val_crf_viterbi_accuracy: 0.7000\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.4205 - crf_viterbi_accuracy: 0.9000 - val_loss: 0.4120 - val_crf_viterbi_accuracy: 0.8000\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 0.5629 - crf_viterbi_accuracy: 0.7667 - val_loss: 0.5401 - val_crf_viterbi_accuracy: 0.7000\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 0.4048 - crf_viterbi_accuracy: 0.9000 - val_loss: 0.4925 - val_crf_viterbi_accuracy: 0.7000\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 0.4186 - crf_viterbi_accuracy: 0.8000 - val_loss: 0.4584 - val_crf_viterbi_accuracy: 0.8000\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.5033 - crf_viterbi_accuracy: 0.8000 - val_loss: 0.6177 - val_crf_viterbi_accuracy: 0.6000\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.4661 - crf_viterbi_accuracy: 0.8000 - val_loss: 0.5163 - val_crf_viterbi_accuracy: 0.8000\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.4094 - crf_viterbi_accuracy: 0.8333 - val_loss: 0.5583 - val_crf_viterbi_accuracy: 0.7000\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.4046 - crf_viterbi_accuracy: 0.8667 - val_loss: 0.5597 - val_crf_viterbi_accuracy: 0.7000\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 0.5574 - crf_viterbi_accuracy: 0.8000 - val_loss: 0.6711 - val_crf_viterbi_accuracy: 0.6000\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.5775 - crf_viterbi_accuracy: 0.7000 - val_loss: 0.4456 - val_crf_viterbi_accuracy: 0.8000\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.4416 - crf_viterbi_accuracy: 0.8333 - val_loss: 0.5268 - val_crf_viterbi_accuracy: 0.7000\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.3923 - crf_viterbi_accuracy: 0.8667 - val_loss: 0.4979 - val_crf_viterbi_accuracy: 0.8000\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.4068 - crf_viterbi_accuracy: 0.8333 - val_loss: 0.5430 - val_crf_viterbi_accuracy: 0.7000\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.3885 - crf_viterbi_accuracy: 0.8667 - val_loss: 0.5698 - val_crf_viterbi_accuracy: 0.7000\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.4396 - crf_viterbi_accuracy: 0.7667 - val_loss: 0.5693 - val_crf_viterbi_accuracy: 0.7000\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.3702 - crf_viterbi_accuracy: 0.8667 - val_loss: 0.5497 - val_crf_viterbi_accuracy: 0.7000\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.3397 - crf_viterbi_accuracy: 0.9000 - val_loss: 0.4277 - val_crf_viterbi_accuracy: 0.9000\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.3578 - crf_viterbi_accuracy: 0.9333 - val_loss: 0.4131 - val_crf_viterbi_accuracy: 0.9000\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.3750 - crf_viterbi_accuracy: 0.8000 - val_loss: 0.6402 - val_crf_viterbi_accuracy: 0.6000\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.4390 - crf_viterbi_accuracy: 0.7667 - val_loss: 0.4737 - val_crf_viterbi_accuracy: 0.8000\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.4116 - crf_viterbi_accuracy: 0.7667 - val_loss: 0.6123 - val_crf_viterbi_accuracy: 0.7000\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.3271 - crf_viterbi_accuracy: 0.9000 - val_loss: 0.4234 - val_crf_viterbi_accuracy: 0.9000\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.3935 - crf_viterbi_accuracy: 0.8000 - val_loss: 0.5829 - val_crf_viterbi_accuracy: 0.7000\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.3514 - crf_viterbi_accuracy: 0.9000 - val_loss: 0.4154 - val_crf_viterbi_accuracy: 0.9000\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.3387 - crf_viterbi_accuracy: 0.9333 - val_loss: 0.4977 - val_crf_viterbi_accuracy: 0.7000\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.3195 - crf_viterbi_accuracy: 0.8667 - val_loss: 0.4155 - val_crf_viterbi_accuracy: 0.9000\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.3179 - crf_viterbi_accuracy: 0.8333 - val_loss: 0.5281 - val_crf_viterbi_accuracy: 0.6000\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.3062 - crf_viterbi_accuracy: 0.9000 - val_loss: 0.4038 - val_crf_viterbi_accuracy: 0.9000\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.3699 - crf_viterbi_accuracy: 0.8333 - val_loss: 0.4588 - val_crf_viterbi_accuracy: 0.8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.2803 - crf_viterbi_accuracy: 0.9333 - val_loss: 0.5458 - val_crf_viterbi_accuracy: 0.7000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbc24493b00>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_model.fit(x=X_train,\n",
    "              y=Y_train,\n",
    "              batch_size=1,\n",
    "              epochs=100,\n",
    "              validation_split=0.1,\n",
    "              verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred2labels(sents, prediction):\n",
    "    pred_labels = []\n",
    "    for sent, pred in zip(sents, prediction):\n",
    "        try:\n",
    "            sent_len = np.where(sent==word2id['__PAD__'])[0][0]\n",
    "        except:\n",
    "            sent_len = max_sent_len\n",
    "\n",
    "        labels = []\n",
    "        for i in range(sent_len):\n",
    "            labels.append(id2label[np.argmax(pred[i])])\n",
    "        pred_labels.append(labels)\n",
    "    return pred_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4,  0,  0,  4],\n",
       "       [ 0,  3,  0,  3],\n",
       "       [ 3,  0,  0,  3],\n",
       "       [ 7,  3,  0, 10]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_size = len(label_list)\n",
    "confusion_matrix = np.zeros((matrix_size+1, matrix_size+1), dtype='int64')\n",
    "\n",
    "prediction = ner_model.predict(X_test)\n",
    "pred_labels = pred2labels(X_test, prediction)\n",
    "test_labels = pred2labels(Y_test, Y_test)\n",
    "\n",
    "for i in range(len(pred_labels)):\n",
    "    for j, pred in enumerate(pred_labels[i]):\n",
    "        row = label2id[test_labels[i][j]]\n",
    "        col = label2id[pred]\n",
    "        confusion_matrix[row, col] += 1\n",
    "\n",
    "for i in range(matrix_size):\n",
    "    confusion_matrix[i, matrix_size] = sum(confusion_matrix[i, 0:matrix_size])\n",
    "    confusion_matrix[matrix_size, i] = sum(confusion_matrix[0:matrix_size, i])\n",
    "\n",
    "confusion_matrix[matrix_size, matrix_size] = sum(matrix[matrix_size, 0:matrix_size])\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_f1_score(p, r):\n",
    "    if p != 0 or r != 0:\n",
    "        return (2*p*r)/(p+r)\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|    [NON]: 0.727\n",
      "|    [PER]: 1.000\n",
      "|    [FOD]: 0.000\n"
     ]
    }
   ],
   "source": [
    "f1_score_list = []\n",
    "matrix_size = len(confusion_matrix)\n",
    "for i in range(matrix_size):\n",
    "    corr = confusion_matrix[i, i]\n",
    "    pred = confusion_matrix[matrix_size-1, i]\n",
    "    real = confusion_matrix[i, matrix_size-1]\n",
    "\n",
    "    precision = corr/max(pred, 1)\n",
    "    recall = corr/max(real, 1)\n",
    "    f1_score_list.append(get_f1_score(p=precision, r=recall))\n",
    "\n",
    "f1_score_average = np.mean(f1_score_list).round(3)\n",
    "\n",
    "for category, f1_score in zip(label_list, f1_score_list):\n",
    "    print('|    [{}]: {:.03f}'.format(category, f1_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Save & Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath_model = 'test/ner/model.pk'\n",
    "ner_model.save(fpath_model)\n",
    "# fpath_dataset = '{}-dataset.pk'.format(fpath_model.replace('.pk', ''))\n",
    "# with open(fpath_dataset, 'wb') as f:\n",
    "#     pk.dump(dataset, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "_input = Input(shape=(max_sent_len, feature_size))\n",
    "ner_model = Bidirectional(LSTM(units=512,\n",
    "                           return_sequences=True,\n",
    "                           recurrent_dropout=0.2))(_input)\n",
    "ner_model = TimeDistributed(Dense(units=100,\n",
    "                              activation='relu'))(ner_model)\n",
    "crf = CRF(len(label2id))\n",
    "_output = crf(ner_model)\n",
    "\n",
    "ner_model = Model(inputs=_input, outputs=_output)\n",
    "ner_model.compile(optimizer='rmsprop',\n",
    "                  loss=crf.loss_function,\n",
    "                  metrics=[crf.accuracy])\n",
    "\n",
    "ner_model.load_weights(fpath_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sent = 'Tom eats apple'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_by_id = []\n",
    "for w in [w.lower() for w in new_sent]:\n",
    "    if w in word2id.keys():\n",
    "        sent_by_id.append(word2id[w])\n",
    "    else:\n",
    "        sent_by_id.append(word2id['__UNK__'])\n",
    "\n",
    "sent_pad = pad_sequences(maxlen=max_sent_len, sequences=[sent_by_id], padding='post', value=word2id['__PAD__'])\n",
    "X_input = np.zeros((1, max_sent_len, feature_size), dtype=list)\n",
    "for j, w_id in enumerate(sent_pad[0]):\n",
    "    for k in range(feature_size):\n",
    "        word = id2word[w_id]\n",
    "        X_input[0, j, k] = word2vector[word][k]\n",
    "\n",
    "prediction = ner_model.predict(X_input)\n",
    "pred_labels = pred2labels(sents=sent_pad, prediction=prediction)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tom/PER eats/NON apple/NON\n"
     ]
    }
   ],
   "source": [
    "output_sent = []\n",
    "for (word, label) in zip(new_sent.split(), pred_labels):\n",
    "    output_sent.append('{}/{}'.format(word, label))\n",
    "print(' '.join(output_sent))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
