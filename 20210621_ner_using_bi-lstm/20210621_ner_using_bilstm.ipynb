{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/blank54/anaconda3/envs/connlp-lstm/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/data/blank54/anaconda3/envs/connlp-lstm/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/data/blank54/anaconda3/envs/connlp-lstm/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/data/blank54/anaconda3/envs/connlp-lstm/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/data/blank54/anaconda3/envs/connlp-lstm/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/data/blank54/anaconda3/envs/connlp-lstm/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/data/blank54/anaconda3/envs/connlp-lstm/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/data/blank54/anaconda3/envs/connlp-lstm/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/data/blank54/anaconda3/envs/connlp-lstm/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/data/blank54/anaconda3/envs/connlp-lstm/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/data/blank54/anaconda3/envs/connlp-lstm/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/data/blank54/anaconda3/envs/connlp-lstm/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from silence_tensorflow import silence_tensorflow\n",
    "silence_tensorflow()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=DeprecationWarning)\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle as pk\n",
    "import itertools\n",
    "from copy import deepcopy\n",
    "from collections import defaultdict\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Model, Input\n",
    "from keras.layers import Dense, Bidirectional, LSTM, TimeDistributed\n",
    "from keras_contrib.layers import CRF\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = {'NON': 0,     #None\n",
    "              'PER': 1,     #PERSON\n",
    "              'FOD': 2,}    #FOOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = deepcopy([l for l in label_dict.keys()])\n",
    "\n",
    "cnt = deepcopy(len(label_dict))\n",
    "label_dict['__PAD__'] = cnt\n",
    "label_dict['__UNK__'] = cnt+1\n",
    "        \n",
    "label2id = label_dict\n",
    "id2label = {int(i): str(l) for i, l in enumerate(label_dict.keys())}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sents = {'sent1': 'Sam likes pizza',\n",
    "              'sent2': 'Erik eats pizza',\n",
    "              'sent3': 'Erik and Sam are drinking soda',\n",
    "              'sent4': 'Flora cooks chicken',\n",
    "              'sent5': 'Sam ordered a chicken',\n",
    "              'sent6': 'Flora likes chicken sandwitch',\n",
    "              'sent7': 'Erik likes to drink soda'}\n",
    "data_labels = {'sent1': [1, 0, 2],\n",
    "               'sent2': [1, 0, 2],\n",
    "               'sent3': [1, 0, 1, 0, 0, 2],\n",
    "               'sent4': [1, 0, 2],\n",
    "               'sent5': [1, 0, 0, 2],\n",
    "               'sent6': [1, 0, 2, 2],\n",
    "               'sent7': [1, 0, 0, 0, 2]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = []\n",
    "for tag, sent in data_sents.items():\n",
    "    words = [str(w) for w in sent.split()]\n",
    "    labels = data_labels[tag]\n",
    "    docs.append((tag, words, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = list(set(itertools.chain(*[doc[1] for doc in docs])))\n",
    "words.append('__PAD__')\n",
    "words.append('__UNK__')\n",
    "\n",
    "word2id = {w: i for i, w in enumerate(words)}\n",
    "id2word = {i: w for i, w in enumerate(words)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sent_len = 10\n",
    "test_size = 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Sentence Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_words = []\n",
    "Y_labels = []\n",
    "for doc in docs:\n",
    "    X_words.append([word2id[w] for w in doc[1]])\n",
    "    Y_labels.append(doc[2])\n",
    "\n",
    "X_words_pad = pad_sequences(\n",
    "    maxlen=max_sent_len,\n",
    "    sequences=X_words,\n",
    "    padding='post',\n",
    "    value=word2id['__PAD__'])\n",
    "Y_labels_pad = pad_sequences(\n",
    "    maxlen=max_sent_len,\n",
    "    sequences=Y_labels,\n",
    "    padding='post',\n",
    "    value=label2id['__PAD__'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_for_w2v = [doc[1] for doc in docs]\n",
    "w2v_model = Word2Vec(sentences=docs_for_w2v,\n",
    "                     size=100,\n",
    "                     window=5,\n",
    "                     min_count=0,\n",
    "                     iter=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vector = {w: w2v_model.wv[w] for w in w2v_model.wv.vocab.keys()}\n",
    "feature_size = w2v_model.vector_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vector['__PAD__'] = np.zeros(feature_size)\n",
    "word2vector['__UNK__'] = np.zeros(feature_size)\n",
    "\n",
    "X_embedded = np.zeros((len(docs), max_sent_len, feature_size))\n",
    "Y_embedded = np.zeros((len(docs), max_sent_len, len(label2id)))\n",
    "\n",
    "for i in range(len(docs)):\n",
    "    for j, word_id in enumerate(X_words_pad[i]):\n",
    "        Y_embedded[i] = to_categorical(Y_labels_pad[i], num_classes=(len(label2id)))\n",
    "        for k in range(feature_size):\n",
    "            word = id2word[word_id]\n",
    "            X_embedded[i, j, k] = word2vector[word][k]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X_embedded, Y_embedded, test_size=test_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Model Development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "_input = Input(shape=(max_sent_len, feature_size))\n",
    "ner_model = Bidirectional(LSTM(units=512,\n",
    "                           return_sequences=True,\n",
    "                           recurrent_dropout=0.2))(_input)\n",
    "ner_model = TimeDistributed(Dense(units=100,\n",
    "                              activation='relu'))(ner_model)\n",
    "crf = CRF(len(label2id))\n",
    "_output = crf(ner_model)\n",
    "\n",
    "ner_model = Model(inputs=_input, outputs=_output)\n",
    "ner_model.compile(optimizer='rmsprop',\n",
    "                  loss=crf.loss_function,\n",
    "                  metrics=[crf.accuracy])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3 samples, validate on 1 samples\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 11s 4s/step - loss: 1.4990 - crf_viterbi_accuracy: 0.0000e+00 - val_loss: 0.9685 - val_crf_viterbi_accuracy: 0.7000\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.8331 - crf_viterbi_accuracy: 0.6333 - val_loss: 0.4936 - val_crf_viterbi_accuracy: 0.7000\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.6303 - crf_viterbi_accuracy: 0.6333 - val_loss: 0.4431 - val_crf_viterbi_accuracy: 0.9000\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 0.5844 - crf_viterbi_accuracy: 0.7333 - val_loss: 0.4093 - val_crf_viterbi_accuracy: 0.9000\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.4889 - crf_viterbi_accuracy: 0.6667 - val_loss: 0.3137 - val_crf_viterbi_accuracy: 0.9000\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 0.5632 - crf_viterbi_accuracy: 0.6333 - val_loss: 0.2904 - val_crf_viterbi_accuracy: 0.9000\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.4551 - crf_viterbi_accuracy: 0.7000 - val_loss: 0.2477 - val_crf_viterbi_accuracy: 0.7000\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 0.4263 - crf_viterbi_accuracy: 0.7000 - val_loss: 0.5139 - val_crf_viterbi_accuracy: 0.7000\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.4194 - crf_viterbi_accuracy: 0.7333 - val_loss: 0.3824 - val_crf_viterbi_accuracy: 0.7000\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.3711 - crf_viterbi_accuracy: 0.7333 - val_loss: 0.2965 - val_crf_viterbi_accuracy: 0.7000\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 0.3868 - crf_viterbi_accuracy: 0.7333 - val_loss: 0.2443 - val_crf_viterbi_accuracy: 0.7000\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.3794 - crf_viterbi_accuracy: 0.7333 - val_loss: 0.4010 - val_crf_viterbi_accuracy: 0.7000\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 0.3536 - crf_viterbi_accuracy: 0.7333 - val_loss: 0.2494 - val_crf_viterbi_accuracy: 0.7000\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.4323 - crf_viterbi_accuracy: 0.7000 - val_loss: 0.3660 - val_crf_viterbi_accuracy: 0.7000\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 0.2958 - crf_viterbi_accuracy: 0.8000 - val_loss: 0.2452 - val_crf_viterbi_accuracy: 0.7000\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 0.3485 - crf_viterbi_accuracy: 0.7333 - val_loss: 0.3289 - val_crf_viterbi_accuracy: 0.7000\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.3618 - crf_viterbi_accuracy: 0.7000 - val_loss: 0.2265 - val_crf_viterbi_accuracy: 0.7000\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 0.3186 - crf_viterbi_accuracy: 0.7333 - val_loss: 0.2481 - val_crf_viterbi_accuracy: 0.7000\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 0.2880 - crf_viterbi_accuracy: 0.7667 - val_loss: 0.1551 - val_crf_viterbi_accuracy: 0.8000\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 0.3016 - crf_viterbi_accuracy: 0.8000 - val_loss: 0.2301 - val_crf_viterbi_accuracy: 0.7000\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.2871 - crf_viterbi_accuracy: 0.7667 - val_loss: 0.3469 - val_crf_viterbi_accuracy: 0.8000\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.4179 - crf_viterbi_accuracy: 0.7667 - val_loss: 0.2579 - val_crf_viterbi_accuracy: 0.7000\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 0.3078 - crf_viterbi_accuracy: 0.8000 - val_loss: 0.3328 - val_crf_viterbi_accuracy: 0.7000\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.2664 - crf_viterbi_accuracy: 0.7667 - val_loss: 0.2975 - val_crf_viterbi_accuracy: 0.7000\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.2658 - crf_viterbi_accuracy: 0.7667 - val_loss: 0.1528 - val_crf_viterbi_accuracy: 0.8000\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.2380 - crf_viterbi_accuracy: 0.8333 - val_loss: 0.6099 - val_crf_viterbi_accuracy: 0.7000\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.2936 - crf_viterbi_accuracy: 0.7333 - val_loss: 0.2562 - val_crf_viterbi_accuracy: 0.9000\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.2987 - crf_viterbi_accuracy: 0.7667 - val_loss: 0.1510 - val_crf_viterbi_accuracy: 0.8000\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 0.2176 - crf_viterbi_accuracy: 0.8000 - val_loss: 0.2478 - val_crf_viterbi_accuracy: 0.8000\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.2332 - crf_viterbi_accuracy: 0.8333 - val_loss: 0.4353 - val_crf_viterbi_accuracy: 0.7000\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.4176 - crf_viterbi_accuracy: 0.7667 - val_loss: 0.2200 - val_crf_viterbi_accuracy: 0.7000\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.2408 - crf_viterbi_accuracy: 0.8000 - val_loss: 0.2712 - val_crf_viterbi_accuracy: 0.8000\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 0.2026 - crf_viterbi_accuracy: 0.8333 - val_loss: 0.1497 - val_crf_viterbi_accuracy: 0.8000\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.3253 - crf_viterbi_accuracy: 0.7667 - val_loss: 0.2532 - val_crf_viterbi_accuracy: 0.7000\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.2134 - crf_viterbi_accuracy: 0.8000 - val_loss: 0.2162 - val_crf_viterbi_accuracy: 0.9000\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 0.3586 - crf_viterbi_accuracy: 0.7667 - val_loss: 0.1734 - val_crf_viterbi_accuracy: 0.8000\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.2374 - crf_viterbi_accuracy: 0.8000 - val_loss: 0.1108 - val_crf_viterbi_accuracy: 0.8000\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 0.2077 - crf_viterbi_accuracy: 0.8333 - val_loss: 0.0985 - val_crf_viterbi_accuracy: 0.8000\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.2965 - crf_viterbi_accuracy: 0.8000 - val_loss: 0.2692 - val_crf_viterbi_accuracy: 0.7000\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.2745 - crf_viterbi_accuracy: 0.8000 - val_loss: 0.1789 - val_crf_viterbi_accuracy: 0.8000\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 0.2049 - crf_viterbi_accuracy: 0.8333 - val_loss: 0.1869 - val_crf_viterbi_accuracy: 0.8000\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 0.2734 - crf_viterbi_accuracy: 0.7667 - val_loss: 0.1090 - val_crf_viterbi_accuracy: 0.8000\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 0.2597 - crf_viterbi_accuracy: 0.7333 - val_loss: 0.2121 - val_crf_viterbi_accuracy: 0.8000\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.1720 - crf_viterbi_accuracy: 0.8333 - val_loss: 0.1166 - val_crf_viterbi_accuracy: 0.8000\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.2315 - crf_viterbi_accuracy: 0.8333 - val_loss: 0.2832 - val_crf_viterbi_accuracy: 0.7000\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 0.2285 - crf_viterbi_accuracy: 0.8000 - val_loss: 0.2084 - val_crf_viterbi_accuracy: 0.8000\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 0.2547 - crf_viterbi_accuracy: 0.7667 - val_loss: 0.1333 - val_crf_viterbi_accuracy: 0.8000\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.1550 - crf_viterbi_accuracy: 0.8333 - val_loss: 0.1986 - val_crf_viterbi_accuracy: 0.8000\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 0.2632 - crf_viterbi_accuracy: 0.8000 - val_loss: 0.2866 - val_crf_viterbi_accuracy: 0.7000\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 70ms/step - loss: 0.3397 - crf_viterbi_accuracy: 0.7333 - val_loss: 0.1333 - val_crf_viterbi_accuracy: 0.8000\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.1706 - crf_viterbi_accuracy: 0.8000 - val_loss: 0.0948 - val_crf_viterbi_accuracy: 0.8000\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.1642 - crf_viterbi_accuracy: 0.8333 - val_loss: 0.1798 - val_crf_viterbi_accuracy: 0.8000\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.1626 - crf_viterbi_accuracy: 0.8333 - val_loss: 0.2245 - val_crf_viterbi_accuracy: 0.8000\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.1499 - crf_viterbi_accuracy: 0.8000 - val_loss: 0.0782 - val_crf_viterbi_accuracy: 0.8000\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.1789 - crf_viterbi_accuracy: 0.8667 - val_loss: 0.1569 - val_crf_viterbi_accuracy: 0.8000\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.1726 - crf_viterbi_accuracy: 0.8333 - val_loss: 0.2480 - val_crf_viterbi_accuracy: 0.7000\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.3074 - crf_viterbi_accuracy: 0.7667 - val_loss: 0.2253 - val_crf_viterbi_accuracy: 0.7000\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 0.1892 - crf_viterbi_accuracy: 0.7667 - val_loss: 0.1309 - val_crf_viterbi_accuracy: 0.8000\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 0.2120 - crf_viterbi_accuracy: 0.8000 - val_loss: 0.0917 - val_crf_viterbi_accuracy: 0.8000\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.1455 - crf_viterbi_accuracy: 0.8333 - val_loss: 0.0775 - val_crf_viterbi_accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.1583 - crf_viterbi_accuracy: 0.8667 - val_loss: 0.2811 - val_crf_viterbi_accuracy: 0.8000\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.1672 - crf_viterbi_accuracy: 0.8333 - val_loss: 0.2540 - val_crf_viterbi_accuracy: 0.8000\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.1568 - crf_viterbi_accuracy: 0.8000 - val_loss: 0.4172 - val_crf_viterbi_accuracy: 0.7000\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 0.3857 - crf_viterbi_accuracy: 0.7000 - val_loss: 0.1363 - val_crf_viterbi_accuracy: 0.8000\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 0.1386 - crf_viterbi_accuracy: 0.8333 - val_loss: 0.2046 - val_crf_viterbi_accuracy: 0.8000\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.1343 - crf_viterbi_accuracy: 0.8667 - val_loss: 0.1857 - val_crf_viterbi_accuracy: 0.8000\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.1119 - crf_viterbi_accuracy: 0.9000 - val_loss: 0.0920 - val_crf_viterbi_accuracy: 0.8000\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 0.1497 - crf_viterbi_accuracy: 0.8000 - val_loss: 0.0572 - val_crf_viterbi_accuracy: 0.8000\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 0.1608 - crf_viterbi_accuracy: 0.8333 - val_loss: 0.2209 - val_crf_viterbi_accuracy: 0.8000\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.1113 - crf_viterbi_accuracy: 0.8333 - val_loss: 0.0932 - val_crf_viterbi_accuracy: 0.8000\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 0.1690 - crf_viterbi_accuracy: 0.8667 - val_loss: 0.2307 - val_crf_viterbi_accuracy: 0.7000\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.1303 - crf_viterbi_accuracy: 0.8667 - val_loss: 0.2474 - val_crf_viterbi_accuracy: 0.8000\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 0.2348 - crf_viterbi_accuracy: 0.8000 - val_loss: 0.2575 - val_crf_viterbi_accuracy: 0.9000\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.1336 - crf_viterbi_accuracy: 0.8333 - val_loss: 0.1923 - val_crf_viterbi_accuracy: 0.7000\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.1122 - crf_viterbi_accuracy: 0.8333 - val_loss: 0.1596 - val_crf_viterbi_accuracy: 0.8000\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 0.1331 - crf_viterbi_accuracy: 0.8333 - val_loss: 0.1081 - val_crf_viterbi_accuracy: 0.8000\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.1005 - crf_viterbi_accuracy: 0.9000 - val_loss: 0.1894 - val_crf_viterbi_accuracy: 0.8000\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 0.2108 - crf_viterbi_accuracy: 0.8000 - val_loss: 0.1829 - val_crf_viterbi_accuracy: 0.8000\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.0784 - crf_viterbi_accuracy: 0.9000 - val_loss: 0.1628 - val_crf_viterbi_accuracy: 0.8000\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 0.0695 - crf_viterbi_accuracy: 0.9000 - val_loss: 0.0722 - val_crf_viterbi_accuracy: 0.9000\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.1238 - crf_viterbi_accuracy: 0.8667 - val_loss: 0.2400 - val_crf_viterbi_accuracy: 0.9000\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 0.2366 - crf_viterbi_accuracy: 0.8333 - val_loss: 0.1656 - val_crf_viterbi_accuracy: 0.8000\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 0.0801 - crf_viterbi_accuracy: 0.9000 - val_loss: 0.1423 - val_crf_viterbi_accuracy: 0.7000\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 0.1400 - crf_viterbi_accuracy: 0.8333 - val_loss: 0.1412 - val_crf_viterbi_accuracy: 0.7000\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.0651 - crf_viterbi_accuracy: 0.8000 - val_loss: 0.0547 - val_crf_viterbi_accuracy: 0.9000\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.0927 - crf_viterbi_accuracy: 0.8667 - val_loss: 0.0360 - val_crf_viterbi_accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 0.0826 - crf_viterbi_accuracy: 0.8333 - val_loss: 0.0804 - val_crf_viterbi_accuracy: 0.9000\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.0520 - crf_viterbi_accuracy: 0.9000 - val_loss: 0.1475 - val_crf_viterbi_accuracy: 0.8000\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 0.1736 - crf_viterbi_accuracy: 0.7667 - val_loss: 0.2884 - val_crf_viterbi_accuracy: 0.7000\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.1554 - crf_viterbi_accuracy: 0.9000 - val_loss: 0.0046 - val_crf_viterbi_accuracy: 0.9000\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.0653 - crf_viterbi_accuracy: 0.8333 - val_loss: 0.0281 - val_crf_viterbi_accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 0.1243 - crf_viterbi_accuracy: 0.8333 - val_loss: 0.1020 - val_crf_viterbi_accuracy: 0.9000\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.1426 - crf_viterbi_accuracy: 0.7667 - val_loss: 0.0169 - val_crf_viterbi_accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 0.0668 - crf_viterbi_accuracy: 0.8667 - val_loss: 0.0729 - val_crf_viterbi_accuracy: 0.8000\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.0917 - crf_viterbi_accuracy: 0.8000 - val_loss: 0.2053 - val_crf_viterbi_accuracy: 0.7000\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.0523 - crf_viterbi_accuracy: 0.9000 - val_loss: 0.1019 - val_crf_viterbi_accuracy: 0.8000\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.1316 - crf_viterbi_accuracy: 0.8667 - val_loss: 0.0285 - val_crf_viterbi_accuracy: 0.8000\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.2716 - crf_viterbi_accuracy: 0.8333 - val_loss: 0.0626 - val_crf_viterbi_accuracy: 0.8000\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.0318 - crf_viterbi_accuracy: 0.9333 - val_loss: 0.0347 - val_crf_viterbi_accuracy: 0.8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.0312 - crf_viterbi_accuracy: 0.9000 - val_loss: 0.0871 - val_crf_viterbi_accuracy: 0.8000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f17a0262950>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_model.fit(x=X_train,\n",
    "              y=Y_train,\n",
    "              batch_size=1,\n",
    "              epochs=100,\n",
    "              validation_split=0.1,\n",
    "              verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred2labels(sents, prediction):\n",
    "    pred_labels = []\n",
    "    for sent, pred in zip(sents, prediction):\n",
    "        try:\n",
    "            sent_len = np.where(sent==word2id['__PAD__'])[0][0]\n",
    "        except:\n",
    "            sent_len = max_sent_len\n",
    "\n",
    "        labels = []\n",
    "        for i in range(sent_len):\n",
    "            labels.append(id2label[np.argmax(pred[i])])\n",
    "        pred_labels.append(labels)\n",
    "    return pred_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4,  0,  1,  5],\n",
       "       [ 1,  3,  0,  4],\n",
       "       [ 0,  0,  2,  2],\n",
       "       [ 5,  3,  3, 11]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_size = len(label_list)\n",
    "confusion_matrix = np.zeros((matrix_size+1, matrix_size+1), dtype='int64')\n",
    "\n",
    "prediction = ner_model.predict(X_test)\n",
    "pred_labels = pred2labels(X_test, prediction)\n",
    "test_labels = pred2labels(Y_test, Y_test)\n",
    "\n",
    "for i in range(len(pred_labels)):\n",
    "    for j, pred in enumerate(pred_labels[i]):\n",
    "        row = label2id[test_labels[i][j]]\n",
    "        col = label2id[pred]\n",
    "        confusion_matrix[row, col] += 1\n",
    "\n",
    "for i in range(matrix_size):\n",
    "    confusion_matrix[i, matrix_size] = sum(confusion_matrix[i, 0:matrix_size])\n",
    "    confusion_matrix[matrix_size, i] = sum(confusion_matrix[0:matrix_size, i])\n",
    "\n",
    "confusion_matrix[matrix_size, matrix_size] = sum(confusion_matrix[matrix_size, 0:matrix_size])\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_f1_score(p, r):\n",
    "    if p != 0 or r != 0:\n",
    "        return (2*p*r)/(p+r)\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|    [NON]: 0.800\n",
      "|    [PER]: 0.857\n",
      "|    [FOD]: 0.800\n"
     ]
    }
   ],
   "source": [
    "f1_score_list = []\n",
    "matrix_size = len(confusion_matrix)\n",
    "for i in range(matrix_size):\n",
    "    corr = confusion_matrix[i, i]\n",
    "    pred = confusion_matrix[matrix_size-1, i]\n",
    "    real = confusion_matrix[i, matrix_size-1]\n",
    "\n",
    "    precision = corr/max(pred, 1)\n",
    "    recall = corr/max(real, 1)\n",
    "    f1_score_list.append(get_f1_score(p=precision, r=recall))\n",
    "\n",
    "f1_score_average = np.mean(f1_score_list).round(3)\n",
    "\n",
    "for category, f1_score in zip(label_list, f1_score_list):\n",
    "    print('|    [{}]: {:.03f}'.format(category, f1_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Save & Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Unable to create file (unable to open file: name = 'test/ner/model.pk', errno = 2, error message = 'No such file or directory', flags = 13, o_flags = 242)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-ee93dfa73bc3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfpath_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'test/ner/model.pk'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mner_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpath_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# fpath_dataset = '{}-dataset.pk'.format(fpath_model.replace('.pk', ''))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# with open(fpath_dataset, 'wb') as f:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#     pk.dump(dataset, f)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/connlp-lstm/lib/python3.7/site-packages/keras/engine/network.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[1;32m   1088\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1089\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msave_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1090\u001b[0;31m         \u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_optimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1091\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1092\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/connlp-lstm/lib/python3.7/site-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(model, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0mopened_new_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/connlp-lstm/lib/python3.7/site-packages/keras/utils/io_utils.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, mode)\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/connlp-lstm/lib/python3.7/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, **kwds)\u001b[0m\n\u001b[1;32m    406\u001b[0m                 fid = make_fid(name, mode, userblock_size,\n\u001b[1;32m    407\u001b[0m                                \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmake_fcpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m                                swmr=swmr)\n\u001b[0m\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/connlp-lstm/lib/python3.7/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_EXCL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfcpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_TRUNC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfcpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'a'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;31m# Open in append mode (read/write).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.create\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Unable to create file (unable to open file: name = 'test/ner/model.pk', errno = 2, error message = 'No such file or directory', flags = 13, o_flags = 242)"
     ]
    }
   ],
   "source": [
    "fpath_model = 'test/ner/model.pk'\n",
    "ner_model.save(fpath_model)\n",
    "# fpath_dataset = '{}-dataset.pk'.format(fpath_model.replace('.pk', ''))\n",
    "# with open(fpath_dataset, 'wb') as f:\n",
    "#     pk.dump(dataset, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "_input = Input(shape=(max_sent_len, feature_size))\n",
    "ner_model = Bidirectional(LSTM(units=512,\n",
    "                           return_sequences=True,\n",
    "                           recurrent_dropout=0.2))(_input)\n",
    "ner_model = TimeDistributed(Dense(units=100,\n",
    "                              activation='relu'))(ner_model)\n",
    "crf = CRF(len(label2id))\n",
    "_output = crf(ner_model)\n",
    "\n",
    "ner_model = Model(inputs=_input, outputs=_output)\n",
    "ner_model.compile(optimizer='rmsprop',\n",
    "                  loss=crf.loss_function,\n",
    "                  metrics=[crf.accuracy])\n",
    "\n",
    "ner_model.load_weights(fpath_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sent = 'Tom eats apple'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_by_id = []\n",
    "for w in [w.lower() for w in new_sent]:\n",
    "    if w in word2id.keys():\n",
    "        sent_by_id.append(word2id[w])\n",
    "    else:\n",
    "        sent_by_id.append(word2id['__UNK__'])\n",
    "\n",
    "sent_pad = pad_sequences(maxlen=max_sent_len, sequences=[sent_by_id], padding='post', value=word2id['__PAD__'])\n",
    "X_input = np.zeros((1, max_sent_len, feature_size), dtype=list)\n",
    "for j, w_id in enumerate(sent_pad[0]):\n",
    "    for k in range(feature_size):\n",
    "        word = id2word[w_id]\n",
    "        X_input[0, j, k] = word2vector[word][k]\n",
    "\n",
    "prediction = ner_model.predict(X_input)\n",
    "pred_labels = pred2labels(sents=sent_pad, prediction=prediction)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PER',\n",
       " 'NON',\n",
       " 'NON',\n",
       " 'FOD',\n",
       " '__PAD__',\n",
       " '__PAD__',\n",
       " '__PAD__',\n",
       " '__PAD__',\n",
       " '__PAD__',\n",
       " '__PAD__']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tom/PER eats/NON apple/NON\n"
     ]
    }
   ],
   "source": [
    "output_sent = []\n",
    "for (word, label) in zip(new_sent.split(), pred_labels):\n",
    "    output_sent.append('{}/{}'.format(word, label))\n",
    "print(' '.join(output_sent))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
